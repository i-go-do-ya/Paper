# Gradient-Based Learning Applied to Document Recognition

## 기본 정보

- **논문 제목**: [Gradient-Based Learning Applied to Document Recognition](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)
- **저자** : Yann LeCun, Léon Bottou, Yoshua Bengio, Patrick Haffner
- **발표 연도** : 1998
- **모델 이름** : LeNet-5

## 논문을 선택한 이유

많은 자료에서 CNN의 입문으로 'ImageNet Classification with Deep Convolutional Neural Networks' 논문을 권장하는 거 같다. 해당 논문은 분명 CNN 분야에 있어 엄청난 업적을 달성했고, 많은 기여를 한 것은 맞다. 하지만, CNN의 근본적인 개념과 이론적 토대를 파악하는데 있어서 'Gradient-Based Learning Applied to Document Recognition' 논문이 더욱 심도 있는 이해를 제공한다고 생각하기 때문에 이 논문을 통해 CNN이 어떻게 시각적 데이터를 처리하고 복잡한 패턴을 인식하는 능력을 개발했는지에 대한 초기 연구를 보고 알고 싶어서 선택했다.

![LeNet5-0](/docs/Img/LeNet5-0.png)


## 요약

이 논문의 주 메시지는 "기존의 패턴인식 시스템에서 hand-designed heuristics를 줄이고(사람이 직접 설계한 heuristics과 feature) 모델이 스스로 데이터로부터 특징을 학습하고 이를 바탁으로 패턴을 인식하는 것이 더 좋은 성능을 가진다" 이다.

따라서 CNN을 이용한 손으로 쓴 숫자를 인식하는데 초점을 맞추고 있는 논문으로 이 논문은 LeNet-5을 소개하고 다룬다. LeNet-5는 여러개의 Convolutional layers과 subsampling layers, fully connected layers으로 구성되어 있다.

![LeNet5-1](/docs/Img/LeNet5-1.png)

## 도입

문자 인식 작업은 다양한 글꼴, 크기, 스타일과 함께 손으로 쓴 문자의 경우 개인의 필체 차이가 크기 때문에 복잡하다. 이미지의 질(변형, 노이즈, 조명 조건)에 따라 인식의 정확도가 크게 달라질 수 있다.

사실 이전 논문들에서 다뤘던 패턴 인식 기법들에서 데이터들은 의도적으로 설계된 데이터다. 사람이 직접 이미지나 패턴에서 중요하다고 생각되는 특징을 정의하고, 이 특징들을 기반으로 알고리즘을 설계하여 패턴을 인식하려고 시도했다. 쉽게 말해 숫자의 윤곽, 각도, 곡선 등과 같은 특징이 이미 사람에 의해 정의되고 이 특징들을 사용하여 숫자를 구별하는 알고리즘을 만들었다.

### 이전의 한계점

당연히 이미 사람에 의해 특징이 정의된 데이터는 문제가 생길 수 밖에 없다. 사람이 정의한 특징은 해당 문제에 대한 사전 지식을 바탕으로 하기 때문에 새로운 문제나 예상치 못한 데이터 변형에 대처하는데 한계가 있을 수 있다. 또한 새로운 유형의 데이터나 변형된 패턴을 사전 지식을 바탕으로 하기 때문에 새로운 문제나 예상치 못한 데이터 변형에 대처하는데 한계가 있을 수 밖에 없고 일반화되지 않을 수 있기 때문에 문제가 된다.

## 방법론

### 전통적인 패턴인식 방법론

전통적인 패턴 인식 기법에서는 모듈 단위로 학습했다. 메인 모듈은 아래와 같이 2가지다.

![LeNet5-2](/docs/Img/LeNet5-2.png)

- Feature Extraction

  - 역활 : 원본 데이터에서 중요한 정보를 뽑아낸다.
  - 낮은 차원으로의 변환 : 원본 데이터는 보통 높은 차원을 가지고 있다. 중요한 정보를 뽑는 과정에서 이 높은 차원의 데이터를 처리 가능한 낮은 차원의 '특징 벡터'로 변환한다.
    - 왜 낮은 차원을 쓰는걸까?
      - 낮은 차원으로 데이터를 요약하면 분류할때 더 쉽게 데이터를 비교하고 판단할 수 있다.
      - 선택된 특징은 입력 데이터의 변형(이미지 크기 변경, 회적)에 강하기 때문에 핵심적인 정보를 보전하면서도 불필요한 변동성을 제거한다.

- Classifier
  - 역활 : 추출된 특징 벡터를 사용하여 데이터가 어떤 카테고리(클래스)에 속하는지 판단한다.
  - 재설계의 필요성 : 새로운 문제에 맞추어 특징을 다시 설계해야 하는 번거로움이 있다.

전통적인 패턴 인식 기법에서는 Gradient를 사용하지 않고 주로 경험적인 방법이나 통계적인 기반에 두었기 때문에 Classifier가 부정확한 결과를 내놓으면 어떤 부분에서 문제가 발생했는지 분석하고 다시 사용된 특징을 수정하거나 추가한다.

### LeNet5

LeNet은 사실 여러 버전이 있고, 이전의 버전들을 거쳐 발전한 것이 해당 논문의 LeNet5모델이다. 이전에는 Gradient를 사용하지 않았지만, 이번 논문에서 다루는 LeNet-5에서 Gradient를 사용하므로써 글자 인식을 위해 스스로 feature를 찾고 학습하는 모델을 만들었다.  

![LeNet5-1](/docs/Img/LeNet5-1.png)

CNN에서 사용되는 Layer는 feature map을 생성하는 방법에 따라 Convolutional layer와 Subsampling layer로 나눌 수 있다.   

* Convolutional layer 
    - 역활 : 이미지에서 고유한 특징을 추출하는데 사용된다.
    - 방식 : 필터(또는 커널)이 입력 이미지를 스캔하고 각 필터는 이미지의 일부분과 내적(dot product)을 계산하여 feature map을 생성한다. 
    - 특징 : 필터로 인해 나오는 feature는 모서리, 색상, 질감, 패턴 등의 이미지의 특정 feature를 추출한다.  
    - 컨볼루션 층의 필터는 학습 과정에서 최적화되기 때문에 즉 네트워크가 학습하면서 필터가 데이터로부터 중요한 특징을 추출하는 방법을 스스로 학습한다.  

* Subsampling layer (Pooling Layer)  
    - 역활 : 이미지의 차원을 축소하여 계산 복잡성을 줄이고, 중요한 정보를 유지하면서 노이즈에 대한 강건성을 높인다.  
    - 방식 : 일정한 window를 통해 해당 영역 내에 대표값(보통은 Max값)을 선택하고 이 대표값으로 원래 영역을 대체한다.
    - 목적 : feature map을 줄이면서 데이터의 중요한 feature를 요약하고 입력 데이터의 작은 변화나 위치 이동에도 일관된 feature을 추출할 수 있도록 한다.  
    - 최대 풀링(Max Pooling)을 사용하는 서브샘플링 층은 2x2 영역에서 가장 큰 값을 선택하여, 전체 이미지의 크기를 축소하면서도 컨볼루션 층에서 추출된 중요한 feature을 유지한다.  


## 결과

결론적으로 CNN을 적용하면서 입력 데이터의 translation, distortion과 같은 topology변화에 영향을 덜 받음을 알 수 있었으며, 이전 모델들과 다른 강건한 모델을 만들 수 있었다. 

![LeNet5-3](/docs/Img/LeNet5-3.png)

